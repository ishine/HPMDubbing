transformer:
  encoder_layer: 5
  encoder_head: 2
  encoder_hidden: 256
  decoder_layer: 7
  decoder_head: 2
  decoder_hidden: 256
  conv_filter_size: 1024
  conv_kernel_size: [9, 1]
  encoder_dropout: 0.2
  decoder_dropout: 0.01
  pre_net_bottleneck: True

Lip_transformer:
  encoder_layer: 4
  encoder_head: 4
  encoder_hidden: 512
  decoder_layer: 7
  decoder_head: 2
  decoder_hidden: 512
  conv_filter_size: 1024
  conv_kernel_size: [9, 1]
  encoder_dropout: 0.2
  decoder_dropout: 0.2

loss_function:
  model: 4
  # 1  # pitch_mae: True  energy_mae: True mel_mse: False
  # 2  # pitch_mae: False  energy_mae: False mel_mse: True
  # 3  # Our method: HPM-Dubbing (remove_scene) for Chem
  # 4  # Our method: HPM-Dubbing (remove_scene) for MovieAnimation

upsample_ConvTranspose:
  resblock: 1
  upsample_rates: [2, 2] # [8,5,2,2]
  upsample_kernel_sizes: [4, 4] # [16,10,4,4]
  upsample_initial_channel: 256
  resblock_kernel_sizes: [ 3,7,11 ]
  resblock_dilation_sizes: [ [ 1,3,5 ], [ 1,3,5 ], [ 1,3,5 ] ]

variance_predictor:
  filter_size: 256
  kernel_size: 3
  dropout: 0.5
  predictor: False

variance_embedding:
  pitch_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the pitch values are not normalized during preprocessing
  energy_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the energy values are not normalized during preprocessing
  n_bins: 256

multi_speaker: True
with_emotion: True

learn_speaker: False # whether use Embedding layer to learn speaker embedding
learn_emotion: False # whether use Embedding layer to learn emotion embedding

max_seq_len: 1000

vocoder:
  model: "HiFi_GAN_220" # support 'HiFi-GAN', 'MelGAN', 'HiFi_GAN_16', "ISTFTNET", "HiFi_GAN_220"
  speaker: "LJSpeech_16KHz" # support  'LJSpeech', 'universal', 'LJSpeech_16KHz'
  vocoder_checkpoint_path: "/data/conggaoxiang/V2C/V2C_Code/HPM_Dubbing/vocoder/HiFi_GAN_220"

Multi_head_Duration_Aligner:
  Multi-Head_Attention: Ture
  Expand_with_Conv-Transpose: Ture
  Fusion_in_advance: False
  ResNet_multi-scales: False

Affective_Prosody_Adaptor:
  Embedding_Augmentation_in_pitch: Ture
  Embedding_Augmentation_in_energy: Ture
  Add_energy_valence: Ture  # Add or Concat
  cascade: Ture
  Use_Scale_attention: False

Stylespeech:
  sampling_rate: 22050
  filter_length: 1024
  hop_length: 256
  win_length: 1024
  max_wav_value: 32768.0
  mel_fmin: 0.0
  mel_fmax: 8000.0
  n_mel_channels: 80
  max_seq_len: 1000
  encoder_layer: 4
  encoder_head: 2
  encoder_hidden: 256
  decoder_layer: 4
  decoder_head: 2
  decoder_hidden: 256
  fft_conv1d_filter_size: 1024
  fft_conv1d_kernel_size: [ 9, 1 ]
  dropout: 0.1
  variance_predictor_filter_size: 256
  variance_predictor_kernel_size: 3
  variance_embedding_kernel_size: 3
  variance_dropout: 0.5
  style_hidden: 256
  style_head: 2
  style_kernel_size: 5
  style_vector_dim: 256
  batch_size: 48
  meta_batch_size: 20
  max_iter: 200000
  meta_iter: 40000
  n_warm_up_step: 4000
  grad_clip_thresh: 1.0
  betas: [ 0.9, 0.98 ]
  eps: 1e-9
